{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4431730,"sourceType":"datasetVersion","datasetId":2595427}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import packages","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.cluster import KMeans\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras import regularizers, layers\n\nfrom collections import defaultdict\nfrom tqdm import tqdm\n\nimport keras_cv","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:35:30.659914Z","iopub.execute_input":"2024-05-04T11:35:30.660521Z","iopub.status.idle":"2024-05-04T11:35:51.896994Z","shell.execute_reply.started":"2024-05-04T11:35:30.66049Z","shell.execute_reply":"2024-05-04T11:35:51.896122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup datasets","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 224\nINPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:35:51.898591Z","iopub.execute_input":"2024-05-04T11:35:51.899247Z","iopub.status.idle":"2024-05-04T11:35:51.903859Z","shell.execute_reply.started":"2024-05-04T11:35:51.899219Z","shell.execute_reply":"2024-05-04T11:35:51.902767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata_df = pd.read_csv('/kaggle/input/skin-cancer-dataset/HAM10000_metadata.csv')\nmetadata_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:35:51.905253Z","iopub.execute_input":"2024-05-04T11:35:51.905625Z","iopub.status.idle":"2024-05-04T11:35:51.978824Z","shell.execute_reply.started":"2024-05-04T11:35:51.905591Z","shell.execute_reply":"2024-05-04T11:35:51.977876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_name = \"skin-cancer-7-classes\"\ndataset_image_path = '/kaggle/input/skin-cancer-dataset/Skin Cancer/Skin Cancer/'","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:35:51.981342Z","iopub.execute_input":"2024-05-04T11:35:51.981626Z","iopub.status.idle":"2024-05-04T11:35:51.985868Z","shell.execute_reply.started":"2024-05-04T11:35:51.981603Z","shell.execute_reply":"2024-05-04T11:35:51.984929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_classes = metadata_df.dx.unique()\nall_classes","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:35:51.986967Z","iopub.execute_input":"2024-05-04T11:35:51.987264Z","iopub.status.idle":"2024-05-04T11:35:52.005854Z","shell.execute_reply.started":"2024-05-04T11:35:51.987241Z","shell.execute_reply":"2024-05-04T11:35:52.004901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_dict = {\n    'bkl': \"benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses)\", \n    'nv': \"melanocytic nevi\",\n    'df': \"dermatofibroma\", \n    'mel': \"melanoma\", \n    'vasc': \"vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage)\", \n    'bcc': \"basal cell carcinoma\", \n    'akiec': \"Actinic keratoses and intraepithelial carcinoma / Bowen's disease\"\n}\n\nclasses_group_dict = {\n    'dangerous': ['mel', 'akiec'],\n    'non-dangerous': ['bkl', 'nv', 'df', 'vasc', 'bcc']\n}\n\nclasses = [\n    'bkl', \n    'nv', \n    'df', \n    'mel', \n    'vasc', \n    'bcc', \n    'akiec'\n]\nnum_classes = len(classes)\nnum_classes, classes","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:35:52.007083Z","iopub.execute_input":"2024-05-04T11:35:52.007685Z","iopub.status.idle":"2024-05-04T11:35:52.017307Z","shell.execute_reply.started":"2024-05-04T11:35:52.007653Z","shell.execute_reply":"2024-05-04T11:35:52.016104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error_count = 0\n\ndata_dict = defaultdict(list)\ncount_dict = defaultdict(int)\nroot_images = []\nroot_labels = []\n\nlimit = 500\n\nfor i in tqdm(metadata_df.index):\n    row = metadata_df.loc[i, [\"image_id\", \"dx\"]]\n    label = row.dx\n    if label not in classes: continue\n    if count_dict[label] >= limit: continue\n        \n    try:\n        image_id = row.image_id\n        path = os.path.join(dataset_image_path, image_id + '.jpg')\n        \n        image = cv2.imread(path)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        count_dict[label] += 1\n        data_dict[label].append(image)\n        root_images.append(image)\n        root_labels.append(label)\n    except:\n        error_count += 1\n        \nprint(\"ErrorCount:\", error_count)\nprint(\"Total Images:\", len(root_images))","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:35:52.018544Z","iopub.execute_input":"2024-05-04T11:35:52.019414Z","iopub.status.idle":"2024-05-04T11:36:57.287334Z","shell.execute_reply.started":"2024-05-04T11:35:52.019388Z","shell.execute_reply":"2024-05-04T11:36:57.286253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pd.Series(root_labels).value_counts())\nplt.figure(figsize=(9, 3))\nsns.countplot(y=pd.Series(root_labels))\nplt.title(\"\\nThe number of images on each labels\\n\", weight=\"bold\")\nplt.xlabel(\"\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:36:57.288859Z","iopub.execute_input":"2024-05-04T11:36:57.28935Z","iopub.status.idle":"2024-05-04T11:36:57.668991Z","shell.execute_reply.started":"2024-05-04T11:36:57.289313Z","shell.execute_reply":"2024-05-04T11:36:57.668049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize origin data","metadata":{}},{"cell_type":"code","source":"def visualize_datasets(images, labels, k=4, cols=4, seed=42):\n\n    if k > len(images): k = len(images)\n    rows = int(np.ceil(k / cols))\n    fig = plt.figure(figsize=(6 * cols, 4 * rows))\n\n    for i in range(k):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.title.set_text(labels[i])\n        plt.imshow(images[i] / 255.0)\n        plt.colorbar()\n        plt.axis('off')\n\n    plt.show()\n\nsample_images = [data_dict[i][0] for i in data_dict.keys()]\nsample_labels = list(data_dict.keys())\nvisualize_datasets(sample_images, sample_labels, k=len(data_dict), cols=3)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:36:57.670131Z","iopub.execute_input":"2024-05-04T11:36:57.670422Z","iopub.status.idle":"2024-05-04T11:37:00.329007Z","shell.execute_reply.started":"2024-05-04T11:36:57.670396Z","shell.execute_reply":"2024-05-04T11:37:00.327951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Kmean Clustering for Segmentation","metadata":{}},{"cell_type":"code","source":"n_clusters=2\n\nrandom.seed(42)\nbatch = [random.choices(data_dict[lab], k=1)[0] for lab in data_dict]\n\nfor i, img in enumerate(batch):\n    \n    w, h, channel = img.shape\n    X = np.reshape(img, (w * h, channel))\n    \n    # Kmeans clustering with 3 clusters\n    kmeans = KMeans(n_clusters, random_state=0, n_init='auto').fit(X)\n\n    pred_label = kmeans.predict(X)\n    pred_label = np.reshape(pred_label, (h, w))\n\n    mask = np.zeros(shape=(h, w, channel))\n    mask_colors = [\n        (0.0, 0.0, 0.0),\n        (0.5, 0.5, 0.5),\n        (1.0, 1.0, 1.0),\n    ]\n\n    # Display image clustering\n    fg, ax = plt.subplots(1, 2, figsize = (15, 5))\n    \n    ax[0].imshow(img / 255.0)\n    ax[0].set_title(f\"{classes[i]}\")\n    ax[0].axis('off')\n    \n    for i in range(n_clusters):\n        mask[pred_label == i] = mask_colors[i % len(mask_colors)]\n        \n    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=2) \n    ax[1].imshow(mask)\n    ax[1].set_title(f'Segmented Mask')\n    ax[1].axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:00.332581Z","iopub.execute_input":"2024-05-04T11:37:00.332931Z","iopub.status.idle":"2024-05-04T11:37:06.337874Z","shell.execute_reply.started":"2024-05-04T11:37:00.332904Z","shell.execute_reply":"2024-05-04T11:37:06.336905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MixUp ","metadata":{}},{"cell_type":"markdown","source":"# Encode datasets","metadata":{}},{"cell_type":"code","source":"x_arr = np.array(root_images)\ny_arr = tf.one_hot([classes.index(label) for label in root_labels], num_classes).numpy()\nx_arr.shape, y_arr.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:06.339146Z","iopub.execute_input":"2024-05-04T11:37:06.339469Z","iopub.status.idle":"2024-05-04T11:37:06.966642Z","shell.execute_reply.started":"2024-05-04T11:37:06.339441Z","shell.execute_reply":"2024-05-04T11:37:06.965661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tensor = tf.constant(x_arr, tf.float32)\ny_tensor = tf.one_hot([classes.index(label) for label in root_labels], num_classes)\nx_tensor.shape, y_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:06.967736Z","iopub.execute_input":"2024-05-04T11:37:06.968018Z","iopub.status.idle":"2024-05-04T11:37:09.185864Z","shell.execute_reply.started":"2024-05-04T11:37:06.967996Z","shell.execute_reply":"2024-05-04T11:37:09.184883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_per_class = 1000\nmix_per_batch = 42\nmixup = keras_cv.layers.Augmenter([\n    keras_cv.layers.MixUp(),\n])\nroot_label_df = pd.DataFrame({\"dx\": root_labels})\n\nx_tensor_mix = None\ny_tensor_mix = None\n\nfor label, count in count_dict.items():\n    \n    num_mix_least = image_per_class - count\n    num_batch = num_mix_least // mix_per_batch\n    num_mix = num_batch * mix_per_batch\n    print(f\"Found {count} image(s) belong to {label}. Generating {num_mix} ({num_batch} batch(s)) by mixup...\")\n    \n    for i in range(num_batch):\n        indices = np.random.choice(count, mix_per_batch, replace=False)\n        real_index = root_label_df[root_label_df.dx == label].index[indices]\n        \n        x_mix = tf.gather(x_tensor, real_index)\n        y_mix = tf.gather(y_tensor, real_index)\n        \n        mix_out = mixup({\"images\": x_mix, \"labels\": y_mix})\n        \n        if x_tensor_mix is None:\n            x_tensor_mix = mix_out[\"images\"]\n            y_tensor_mix = mix_out[\"labels\"]\n        else:\n            x_tensor_mix = tf.concat([x_tensor_mix, mix_out[\"images\"]], axis=0)\n            y_tensor_mix = tf.concat([y_tensor_mix, mix_out[\"labels\"]], axis=0)\n        \n    \n    print(f\"Mixup complete. {label}: {count + num_mix} image(s).\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:09.186865Z","iopub.execute_input":"2024-05-04T11:37:09.18712Z","iopub.status.idle":"2024-05-04T11:37:11.225696Z","shell.execute_reply.started":"2024-05-04T11:37:09.187098Z","shell.execute_reply":"2024-05-04T11:37:11.224664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize MixUp","metadata":{}},{"cell_type":"code","source":"mix_length = x_tensor_mix.shape[0]\nsample_indices = np.random.choice(mix_length, size=9)\nsample_images = tf.gather(x_tensor_mix, sample_indices).numpy()\nsample_labels = tf.gather(tf.argmax(y_tensor_mix, axis=-1), sample_indices).numpy()\nsample_labels = [classes[i] for i in sample_labels]\nvisualize_datasets(sample_images, sample_labels, k=9, cols=3)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:11.22675Z","iopub.execute_input":"2024-05-04T11:37:11.227041Z","iopub.status.idle":"2024-05-04T11:37:14.370327Z","shell.execute_reply.started":"2024-05-04T11:37:11.227016Z","shell.execute_reply":"2024-05-04T11:37:14.369398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merge Mixup Data","metadata":{}},{"cell_type":"code","source":"x_merge_mix = np.concatenate((x_arr, x_tensor_mix.numpy()), axis=0)\ny_merge_mix = np.concatenate((y_arr, y_tensor_mix.numpy()), axis=0)\n\nx_merge_mix.shape, y_merge_mix.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:14.371656Z","iopub.execute_input":"2024-05-04T11:37:14.371988Z","iopub.status.idle":"2024-05-04T11:37:18.681507Z","shell.execute_reply.started":"2024-05-04T11:37:14.371959Z","shell.execute_reply":"2024-05-04T11:37:18.680638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mixed_labels = [classes[i] for i in np.argmax(y_merge_mix, axis=1)]\nprint(pd.Series(mixed_labels).value_counts())\nplt.figure(figsize=(9, 3))\nsns.countplot(y=pd.Series(mixed_labels))\nplt.title(\"\\nThe number of images on each labels after MixUp\\n\", weight=\"bold\")\nplt.xlabel(\"\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:18.682687Z","iopub.execute_input":"2024-05-04T11:37:18.68304Z","iopub.status.idle":"2024-05-04T11:37:19.00662Z","shell.execute_reply.started":"2024-05-04T11:37:18.683014Z","shell.execute_reply":"2024-05-04T11:37:19.005617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split datasets","metadata":{}},{"cell_type":"code","source":"x = x_merge_mix\ny = y_merge_mix","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:19.008006Z","iopub.execute_input":"2024-05-04T11:37:19.008417Z","iopub.status.idle":"2024-05-04T11:37:19.013226Z","shell.execute_reply.started":"2024-05-04T11:37:19.008382Z","shell.execute_reply":"2024-05-04T11:37:19.01228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and remaining sets (validation + test)\nx_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n# Split the remaining data into validation and test sets\nx_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n\n[\n    x_train.shape, \n    x_val.shape, \n    x_test.shape, \n    y_train.shape , \n    y_val.shape,\n    y_test.shape\n]","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:19.014641Z","iopub.execute_input":"2024-05-04T11:37:19.014977Z","iopub.status.idle":"2024-05-04T11:37:20.529769Z","shell.execute_reply.started":"2024-05-04T11:37:19.014951Z","shell.execute_reply":"2024-05-04T11:37:20.52883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"def plot_acc(model_history, name):\n    plt.rcParams.update({'font.size': 14})\n    print('\\n\\n')\n    epochs = len(model_history.history[\"accuracy\"])\n    plt.figure(figsize=(12,8))\n    plt.plot(np.arange(0, epochs), model_history.history[\"accuracy\"], label=\"train_acc\", marker=\"o\")\n    plt.plot(np.arange(0, epochs), model_history.history[\"val_accuracy\"], label=\"val_acc\", marker=\"o\")\n    plt.title(\"Training Accuracy - {}\".format(name))\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.53119Z","iopub.execute_input":"2024-05-04T11:37:20.531609Z","iopub.status.idle":"2024-05-04T11:37:20.539522Z","shell.execute_reply.started":"2024-05-04T11:37:20.531574Z","shell.execute_reply":"2024-05-04T11:37:20.538538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(model_history, name):\n    plt.rcParams.update({'font.size': 14})\n    print('\\n\\n')\n    epochs = len(model_history.history[\"loss\"])\n    plt.figure(figsize=(12,8))\n    plt.plot(np.arange(0, epochs), model_history.history[\"loss\"], label=\"train_loss\", marker=\"o\")\n    plt.plot(np.arange(0, epochs), model_history.history[\"val_loss\"], label=\"val_loss\", marker=\"o\")\n    plt.title(\"Training Loss - {}\".format(name))\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.541075Z","iopub.execute_input":"2024-05-04T11:37:20.541352Z","iopub.status.idle":"2024-05-04T11:37:20.550522Z","shell.execute_reply.started":"2024-05-04T11:37:20.541329Z","shell.execute_reply":"2024-05-04T11:37:20.549414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to plot confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.rcParams.update({'font.size': 14})\n    \n    # plot the confusion matrix\n    class_count = len(classes)\n    if normalize:\n        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n        \n    plt.figure(figsize=(12, 8))\n    sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n    plt.xticks(np.arange(class_count) + 0.5, classes, rotation=90)\n    plt.yticks(np.arange(class_count) + 0.5, classes, rotation=0)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(title)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.551615Z","iopub.execute_input":"2024-05-04T11:37:20.551942Z","iopub.status.idle":"2024-05-04T11:37:20.561141Z","shell.execute_reply.started":"2024-05-04T11:37:20.551917Z","shell.execute_reply":"2024-05-04T11:37:20.560136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, x, y):\n    scores = model.evaluate(x, y, verbose=1)\n    return scores","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.562395Z","iopub.execute_input":"2024-05-04T11:37:20.562757Z","iopub.status.idle":"2024-05-04T11:37:20.574633Z","shell.execute_reply.started":"2024-05-04T11:37:20.562723Z","shell.execute_reply":"2024-05-04T11:37:20.573516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_prob(model):\n    return model.predict(x_test, batch_size=BATCH_SIZE, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.575898Z","iopub.execute_input":"2024-05-04T11:37:20.576189Z","iopub.status.idle":"2024-05-04T11:37:20.584929Z","shell.execute_reply.started":"2024-05-04T11:37:20.576164Z","shell.execute_reply":"2024-05-04T11:37:20.583889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model):\n    predictions = predict_prob(model)\n    return np.argmax(predictions, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.586528Z","iopub.execute_input":"2024-05-04T11:37:20.587075Z","iopub.status.idle":"2024-05-04T11:37:20.594609Z","shell.execute_reply.started":"2024-05-04T11:37:20.587037Z","shell.execute_reply":"2024-05-04T11:37:20.593614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_metrics(y_true, y_pred):\n    \n    # precision tp / (tp + fp)\n    precision = precision_score(y_true, y_pred, average='weighted')\n    print(\"Precision: {}\".format(precision))\n\n    # recall: tp / (tp + fn)\n    recall = recall_score(y_true, y_pred, average='weighted')\n    print(\"Recall:    {}\".format(recall))\n\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    print(\"F1:        {}\".format(f1))","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.5958Z","iopub.execute_input":"2024-05-04T11:37:20.596135Z","iopub.status.idle":"2024-05-04T11:37:20.604041Z","shell.execute_reply.started":"2024-05-04T11:37:20.596109Z","shell.execute_reply":"2024-05-04T11:37:20.603098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup Training","metadata":{}},{"cell_type":"code","source":"early_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    mode='max',\n    patience=15,\n    restore_best_weights=True,\n    verbose=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.605332Z","iopub.execute_input":"2024-05-04T11:37:20.605713Z","iopub.status.idle":"2024-05-04T11:37:20.613722Z","shell.execute_reply.started":"2024-05-04T11:37:20.605679Z","shell.execute_reply":"2024-05-04T11:37:20.612747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transfer_learning(model, name, epochs=30):\n    \n    best_weights_ph1 = f\"{dataset_name}_{name}_ph1_weights.keras\"\n    \n    callbacks_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath = best_weights_ph1,\n        monitor = \"val_accuracy\",\n        mode = \"max\",\n        save_weights_only=True,\n        save_best_only = True,\n        verbose=1, # Logging when callback running\n    )\n    \n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n    model.compile(\n        optimizer=optimizer, \n        loss='categorical_crossentropy', \n        metrics=[\n            'accuracy', \n        ]\n    )\n    \n    print(\"Model summary for transfer learning: \")\n    print(\"Total params: {:.2f}M\".format(sum(layer.count_params() for layer in model.layers) / 1e6))\n    print(\"Trainable params: {:.2f}M\".format(sum(layer.count_params() if layer.trainable else 0 for layer in model.layers) / 1e6))\n    print(\"Non-Trainable params: {:.2f}M\".format(sum(layer.count_params() if not layer.trainable else 0 for layer in model.layers) / 1e6))\n    \n    history = model.fit(\n        x_train,\n        y_train,\n        batch_size=BATCH_SIZE,\n        validation_data=(x_val, y_val),\n        validation_batch_size=BATCH_SIZE,\n        epochs = epochs,\n        callbacks = [callbacks_checkpoint, early_stop]\n    )\n    \n    acc_max = max(history.history[\"accuracy\"])\n    acc_min = min(history.history[\"accuracy\"])\n    print(\"Training Acc:\", [acc_min, acc_max])\n    \n    val_acc_max = max(history.history[\"val_accuracy\"])\n    val_acc_min = min(history.history[\"val_accuracy\"])\n    print(\"Validation Acc:\", [val_acc_min, val_acc_max])\n    \n    best_idx = np.argmax(history.history[\"val_accuracy\"])\n    print('The best val_acc result expected at epoch {} with metrics: '.format(best_idx + 1))\n    \n    for k, vals in history.history.items():\n        print('{}: {}'.format(k, vals[best_idx]))\n    \n    print('\\nRestoring best weights and predicting validation set.')\n    model.load_weights(best_weights_ph1)\n    model.save(f\"{dataset_name}_{name}_ph1_model.h5\")\n    \n    loss, acc, *other_acc = evaluate(model, x_test, y_test)\n    print('Transfer Learning test scores (loss, acc):', [loss, acc])\n    plot_acc(history, f\"\\n Transfer Learning - ACC: {name} PhA.\")\n    plot_loss(history, f\"\\n Transfer Learning - LOSS: {name} PhA.\")\n    y_pred = predict(model)\n    return history, model, val_acc_max, y_pred","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.614992Z","iopub.execute_input":"2024-05-04T11:37:20.615383Z","iopub.status.idle":"2024-05-04T11:37:20.630246Z","shell.execute_reply.started":"2024-05-04T11:37:20.615349Z","shell.execute_reply":"2024-05-04T11:37:20.629255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup fine tuning","metadata":{}},{"cell_type":"code","source":"def fine_turning(model, name, acc_ph1=0, epochs=60):\n    \n    best_weights_ph2 = f\"{dataset_name}_{name}_ph2_weights.keras\"\n    callbacks_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath = best_weights_ph2, \n        monitor = \"val_accuracy\", \n        mode = \"max\",\n        initial_value_threshold=acc_ph1,\n        save_weights_only=True, \n        save_best_only = True, \n        verbose=1, # Logging when callback running\n    )\n    \n    model.trainable = True\n#     for layer in model.layers:\n#         if not isinstance(layer, layers.BatchNormalization) and not isinstance(layer, layers.LayerNormalization):\n#             layer.trainable = True\n    \n    \n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n    model.compile(\n        optimizer=optimizer, \n        loss='categorical_crossentropy', \n        metrics=[\n            'accuracy', \n        ]\n    )\n    print(\"Model summary for fine tuning: \")\n    print(\"Total params: {:.2f}M\".format(sum(layer.count_params() for layer in model.layers) / 1e6))\n    print(\"Trainable params: {:.2f}M\".format(sum(layer.count_params() if layer.trainable else 0 for layer in model.layers) / 1e6))\n    print(\"Non-Trainable params: {:.2f}M\".format(sum(layer.count_params() if not layer.trainable else 0 for layer in model.layers) / 1e6))\n    \n    history = model.fit(\n        x_train, \n        y_train,\n        batch_size=BATCH_SIZE,\n        validation_data=(x_val, y_val),\n        validation_batch_size=BATCH_SIZE,\n        epochs = epochs,\n        callbacks = [callbacks_checkpoint, early_stop]\n    )\n    \n    acc_max = max(history.history[\"accuracy\"])\n    acc_min = min(history.history[\"accuracy\"])\n    print(\"Training Acc:\", [acc_min, acc_max])\n    \n    val_acc_max = max(history.history[\"val_accuracy\"])\n    val_acc_min = min(history.history[\"val_accuracy\"])\n    print(\"Validation Acc:\", [val_acc_min, val_acc_max])\n    \n    best_idx = np.argmax(history.history[\"val_accuracy\"])\n    print('The best val_acc result expected at epoch {} with metrics: '.format(best_idx))\n    for k, vals in history.history.items():\n        print('{}: {}'.format(k, vals[best_idx]))\n    \n    print('Restoring best weights of Ph2 and predicting test set.')\n    model.load_weights(best_weights_ph2)\n    model.save(f\"{dataset_name}_{name}_ph2_model.h5\")\n    \n    loss, acc, *other_acc = evaluate(model, x_test, y_test)\n    print('Fine Tuning test scores (loss, acc):', [loss, acc])\n    \n    if val_acc_max < acc_ph1:\n        print('\\nPhase 2 resulted in lower accuracy than Phase 1.')\n    \n    plot_acc(history, f\"\\n Fine Tuning - ACC: {name} PhB.\")\n    plot_loss(history, f\"\\n Fine Tuning - LOSS: {name} PhB.\")\n    \n    y_pred = predict(model)\n    return history, model, val_acc_max, y_pred","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.636255Z","iopub.execute_input":"2024-05-04T11:37:20.63656Z","iopub.status.idle":"2024-05-04T11:37:20.650862Z","shell.execute_reply.started":"2024-05-04T11:37:20.636537Z","shell.execute_reply":"2024-05-04T11:37:20.649863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup save history","metadata":{}},{"cell_type":"code","source":"def save_history(history, path):\n    history_df = pd.DataFrame(data=history)\n    history_df.index.name = \"Epoch\"\n    history_df.to_csv(path)\n    print(\"Saved history completed.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.652229Z","iopub.execute_input":"2024-05-04T11:37:20.652598Z","iopub.status.idle":"2024-05-04T11:37:20.662464Z","shell.execute_reply.started":"2024-05-04T11:37:20.652564Z","shell.execute_reply":"2024-05-04T11:37:20.66149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"markdown","source":"# Define Model Holder","metadata":{}},{"cell_type":"code","source":"class ExpModel:\n    \n    priority = 0\n    \n    def __init__(self, model, name, pretrained=True, priority=None, is_ready=True):\n        \n        self.model = model\n        self.name = name\n        self.pretrained = pretrained\n        self.priority = priority\n        if self.priority is None:\n            ExpModel.priority += 1\n            self.priority = ExpModel.priority\n        self.is_ready = is_ready\n\nexp_models = dict()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.66368Z","iopub.execute_input":"2024-05-04T11:37:20.664262Z","iopub.status.idle":"2024-05-04T11:37:20.67135Z","shell.execute_reply.started":"2024-05-04T11:37:20.664234Z","shell.execute_reply":"2024-05-04T11:37:20.67049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet50","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.ResNet50(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='ResNet50')\n\nmodel = build_model()\nexp_models['ResNet50'] = ExpModel(model, 'ResNet50', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:20.672363Z","iopub.execute_input":"2024-05-04T11:37:20.672612Z","iopub.status.idle":"2024-05-04T11:37:23.541816Z","shell.execute_reply.started":"2024-05-04T11:37:20.67259Z","shell.execute_reply":"2024-05-04T11:37:23.540905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DenseNet169","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.DenseNet169(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='DenseNet169')\n\nmodel = build_model()\nexp_models['DenseNet169'] = ExpModel(model, 'DenseNet169', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:23.542967Z","iopub.execute_input":"2024-05-04T11:37:23.54325Z","iopub.status.idle":"2024-05-04T11:37:30.07266Z","shell.execute_reply.started":"2024-05-04T11:37:23.54321Z","shell.execute_reply":"2024-05-04T11:37:30.071727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Xception","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.Xception(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='Xception')\n\nmodel = build_model()\nexp_models['Xception'] = ExpModel(model, 'Xception', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:30.073888Z","iopub.execute_input":"2024-05-04T11:37:30.074186Z","iopub.status.idle":"2024-05-04T11:37:32.369208Z","shell.execute_reply.started":"2024-05-04T11:37:30.07416Z","shell.execute_reply":"2024-05-04T11:37:32.368267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MobileNet","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.MobileNet(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    \n    # Fully Connected Layers\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.35)(x)\n    \n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='MobileNet')\n\nmodel = build_model()\nexp_models['MobileNet'] = ExpModel(model, 'MobileNet', is_ready=True)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:32.370396Z","iopub.execute_input":"2024-05-04T11:37:32.370701Z","iopub.status.idle":"2024-05-04T11:37:33.644006Z","shell.execute_reply.started":"2024-05-04T11:37:32.370667Z","shell.execute_reply":"2024-05-04T11:37:33.643101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet B0 - B7","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.EfficientNetB0(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    \n    \n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='EfficientNetB0')\n\nmodel = build_model()\nexp_models['EfficientNetB0'] = ExpModel(model, 'EfficientNetB0', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:33.645029Z","iopub.execute_input":"2024-05-04T11:37:33.645313Z","iopub.status.idle":"2024-05-04T11:37:36.494451Z","shell.execute_reply.started":"2024-05-04T11:37:33.645288Z","shell.execute_reply":"2024-05-04T11:37:36.493489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained = tf.keras.applications.EfficientNetB4(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    \n    # Fully Connected Layers\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.35)(x)\n    \n    output = layers.Dense(num_classes, activation='softmax')(x)\n    return tf.keras.Model(x_input, output, name='EfficientNetB4')\n\nmodel = build_model()\nexp_models['EfficientNetB4'] = ExpModel(model, 'EfficientNetB4', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:36.495711Z","iopub.execute_input":"2024-05-04T11:37:36.49602Z","iopub.status.idle":"2024-05-04T11:37:41.839086Z","shell.execute_reply.started":"2024-05-04T11:37:36.495995Z","shell.execute_reply":"2024-05-04T11:37:41.838179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"filtered_models = list(filter(lambda obj: obj.is_ready, sorted(exp_models.values(), key=lambda obj: obj.priority)))\nexpected_acc = 0.99\nfor current_model in filtered_models:\n    \n    best_acc = 0\n    print(f'\\n\\n ==========Start Process with model {current_model.name}=========')\n    if current_model.pretrained:\n        history, model, best_acc, y_pred = transfer_learning(current_model.model, current_model.name)\n        y_true = np.argmax(y_test, axis=1)\n        calculate_metrics(y_true, y_pred)\n        cm = confusion_matrix(y_true, y_pred)\n        plot_confusion_matrix(cm, classes, title=f\"Confusion matrix for {current_model.name} - Transfer Learning\")\n        save_history(history.history, f\"{current_model.name}-{dataset_name}-transfer-learning-results.csv\")\n    \n    if best_acc < expected_acc:\n        history, model, best_acc, y_pred = fine_turning(current_model.model, current_model.name, best_acc)\n        y_true = np.argmax(y_test, axis=1)\n        calculate_metrics(y_true, y_pred)\n        cm = confusion_matrix(y_true, y_pred)\n        plot_confusion_matrix(cm, classes, title=f\"Confusion matrix for {current_model.name} - Fine Turnning\")\n        save_history(history.history, f\"{current_model.name}-{dataset_name}-fine-tuning-results.csv\")\n    \n    print(\"Classification Report for {}\".format(current_model.name))\n    print(classification_report(y_true, y_pred, target_names=classes))\n    \n    print(f'\\n\\n ==========Completed Process with model {current_model.name}=========')","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:37:41.840439Z","iopub.execute_input":"2024-05-04T11:37:41.840751Z","iopub.status.idle":"2024-05-04T11:55:22.285547Z","shell.execute_reply.started":"2024-05-04T11:37:41.840725Z","shell.execute_reply":"2024-05-04T11:55:22.284572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explainable SHAP","metadata":{}},{"cell_type":"code","source":"import shap","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:55:22.290493Z","iopub.execute_input":"2024-05-04T11:55:22.290762Z","iopub.status.idle":"2024-05-04T11:55:23.184904Z","shell.execute_reply.started":"2024-05-04T11:55:22.290739Z","shell.execute_reply":"2024-05-04T11:55:23.183796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def explain_model(model, arr, label, k=2):\n    \n    plt.rcParams.update({'font.size': 12})\n    # define a masker that is used to mask out partitions of the input image.\n    masker = shap.maskers.Image(\"inpaint_telea\", INPUT_SHAPE)\n    # create an explainer with model and image masker\n    explainer = shap.Explainer(model, masker, output_names=classes)\n    \n    # here we explain two images using 512 evaluations of the underlying model to estimate the SHAP values\n    print('There are predicted results with model explaination:')\n    x_indices = np.random.choice(arr.shape[0], size=k, replace=False)\n    x_explained = arr[x_indices]\n    \n    for i in range(k):\n        shap_values = explainer(\n            x_explained[i:i+1], max_evals=512, batch_size=BATCH_SIZE, outputs=shap.Explanation.argsort.flip[:len(classes)]\n        )\n        # output with shap values\n        shap.image_plot(shap_values, true_labels=[label], labelpad=10)\n\nexplain_data = { label: np.stack(items) for label, items in data_dict.items() }\nexplain_model","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:55:23.186255Z","iopub.execute_input":"2024-05-04T11:55:23.186947Z","iopub.status.idle":"2024-05-04T11:55:23.327668Z","shell.execute_reply.started":"2024-05-04T11:55:23.186911Z","shell.execute_reply":"2024-05-04T11:55:23.326633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for current_model in filtered_models:\n    if not current_model.is_ready: continue\n    print(f'Explain model for {current_model.name}')\n    for ground_truth, data in explain_data.items():\n        explain_model(current_model.model, data, ground_truth, 2)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T11:55:23.329348Z","iopub.execute_input":"2024-05-04T11:55:23.329778Z","iopub.status.idle":"2024-05-04T12:00:06.091919Z","shell.execute_reply.started":"2024-05-04T11:55:23.329742Z","shell.execute_reply":"2024-05-04T12:00:06.090879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test and Visualize Results","metadata":{}},{"cell_type":"code","source":"k = 5\nn = len(y_test)\nsample_idx = np.random.choice(range(n), k)\nx_sample = x_test[sample_idx]\ny_sample = y_test[sample_idx]\ny_sample.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:00:06.09304Z","iopub.execute_input":"2024-05-04T12:00:06.09332Z","iopub.status.idle":"2024-05-04T12:00:06.101315Z","shell.execute_reply.started":"2024-05-04T12:00:06.093294Z","shell.execute_reply":"2024-05-04T12:00:06.100375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams.update({'font.size': 16})\n\ndef format_label(label):\n    return '\\n'.join(label.split())\n\nshort_labels = list(map(format_label, classes))\nfor current_model in filtered_models:\n    if not current_model.is_ready: continue\n    model = current_model.model\n    print(\"\\n\\nPrediction for {} model\".format(current_model.name))\n    y_pred = model.predict(x_sample)\n    fig, ax = plt.subplots(k, 2, figsize=(30, 25))\n    y_true = np.argmax(y_sample, axis=1)\n    for i in range(k):\n        acc = y_pred[i] * 100\n        bar_colors = ['red', 'blue', 'green', 'orange', 'purple', 'gray', 'magenta']\n        ax[i, 0].imshow(x_sample[i] / 255)\n        ax[i, 0].axis('off')\n        ax[i, 1].bar(short_labels, acc, label=short_labels, color=[bar_colors[i % len(bar_colors)] for i in range(num_classes)])\n        ax[i, 1].set_ylabel('Predict')\n        ax[i, 1].set_title('Ground Truth: {}'.format(classes[y_true[i]]))\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:00:06.102638Z","iopub.execute_input":"2024-05-04T12:00:06.103006Z","iopub.status.idle":"2024-05-04T12:00:09.529233Z","shell.execute_reply.started":"2024-05-04T12:00:06.102973Z","shell.execute_reply":"2024-05-04T12:00:09.528118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}